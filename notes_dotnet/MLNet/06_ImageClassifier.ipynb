{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML.NET Image Classification APIを使用した画像分類（転移学習）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML.NET Image Classification API を使用することで画像分類ができる。事前トレーニング済みの`ResNet v2`を使用して転移学習する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Installing package Microsoft.ML.Vision, version 1.4.0.done!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully added reference to package Microsoft.ML.Vision, version "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Installing package SciSharp.TensorFlow.Redist, version 1.15.0.done!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully added reference to package SciSharp.TensorFlow.Redist, version "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Installing package Microsoft.ML.ImageAnalytics, version 1.4.0.done!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully added reference to package Microsoft.ML.ImageAnalytics, version "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget:Microsoft.ML.Vision, 1.4.0\"\n",
    "#r \"nuget:SciSharp.TensorFlow.Redist , 1.15.0\"\n",
    "#r \"nuget:Microsoft.ML.ImageAnalytics, 1.4.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "using System;\n",
    "using System.Collections.Generic;\n",
    "using System.Linq;\n",
    "using System.IO;\n",
    "using Microsoft.ML;\n",
    "using static Microsoft.ML.DataOperationsCatalog;\n",
    "using Microsoft.ML.Vision;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "public class ImageData\n",
    "{\n",
    "    public string ImagePath { get; set; }\n",
    "    public string Label { get; set; }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入出力データのスキーマ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 入力データスキーマ\n",
    "public class ModelInput\n",
    "{\n",
    "    // 画像のバイト表現\n",
    "    public byte[] Image { get; set; }\n",
    "    // ラベルの数値表現\n",
    "    public UInt32 LabelAsKey { get; set; }\n",
    "    // 画像の完全修飾パス\n",
    "    public string ImagePath { get; set; }\n",
    "    // ラベル（予測すべき値）\n",
    "    public string Label { get; set; }\n",
    "}\n",
    "\n",
    "// 出力データスキーマ\n",
    "public class ModelOutput\n",
    "{\n",
    "    // 画像の完全修飾パス\n",
    "    public string ImagePath { get; set; }\n",
    "    // 正解ラベル\n",
    "    public string Label { get; set; }\n",
    "    // 予測ラベル\n",
    "    public string PredictedLabel { get; set; }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パスの定義と変数の初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C:\\Data\\Study\\Jupyter\\jupyter_notes\\notes_dotnet\\MLNet"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "C:\\Data\\Study\\Jupyter\\jupyter_notes\\notes_dotnet\\MLNet\\workspace"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "C:\\Data\\Study\\Jupyter\\jupyter_notes\\notes_dotnet\\MLNet\\data\\concrete_deck_cracked"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var projectDirectory = Path.GetFullPath(Environment.CurrentDirectory);\n",
    "var workspaceRelativePath = Path.Combine(projectDirectory, \"workspace\");\n",
    "var assetsRelativePath = Path.Combine(projectDirectory, \"data\", \"concrete_deck_cracked\");\n",
    "\n",
    "display(projectDirectory);\n",
    "display(workspaceRelativePath);\n",
    "display(assetsRelativePath);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLContext mlContext = new MLContext();\n",
    "var useFolderNameAsLabel = true;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 指定したディレクトリの画像をImageDataのコレクションとして取得するメソッド\n",
    "public static IEnumerable<ImageData> LoadImagesFromDirectory(string folder, bool useFolderNameAsLabel = true)\n",
    "{\n",
    "    // folder内のすべてのファイル\n",
    "    var files = Directory.GetFiles(folder, \"*\", searchOption: SearchOption.AllDirectories);\n",
    "\n",
    "    foreach (var file in files)\n",
    "    {\n",
    "        // ファイル拡張子がAPIでサポートされているjpg/pngであることを確認\n",
    "        if ((Path.GetExtension(file) != \".jpg\") && (Path.GetExtension(file) != \".png\")) continue;\n",
    "    \n",
    "        var label = Path.GetFileName(file);\n",
    "\n",
    "        if (useFolderNameAsLabel) \n",
    "        {\n",
    "            label = Directory.GetParent(file).Name;\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            for (int index = 0; index < label.Length; index++)\n",
    "            {\n",
    "                if (!char.IsLetter(label[index]))\n",
    "                {\n",
    "                    label = label.Substring(0, index);\n",
    "                    break;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "        yield return new ImageData(){ImagePath = file, Label = label};\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th><i>index</i></th><th>ImagePath</th><th>Label</th></tr></thead><tbody><tr><td>0</td><td>C:\\Data\\Study\\Jupyter\\jupyter_notes\\notes_dotnet\\MLNet\\data\\concrete_deck_cracked\\CD\\7001-115.jpg</td><td>CD</td></tr><tr><td>1</td><td>C:\\Data\\Study\\Jupyter\\jupyter_notes\\notes_dotnet\\MLNet\\data\\concrete_deck_cracked\\CD\\7001-139.jpg</td><td>CD</td></tr><tr><td>2</td><td>C:\\Data\\Study\\Jupyter\\jupyter_notes\\notes_dotnet\\MLNet\\data\\concrete_deck_cracked\\CD\\7001-151.jpg</td><td>CD</td></tr><tr><td>3</td><td>C:\\Data\\Study\\Jupyter\\jupyter_notes\\notes_dotnet\\MLNet\\data\\concrete_deck_cracked\\CD\\7001-157.jpg</td><td>CD</td></tr><tr><td>4</td><td>C:\\Data\\Study\\Jupyter\\jupyter_notes\\notes_dotnet\\MLNet\\data\\concrete_deck_cracked\\CD\\7001-169.jpg</td><td>CD</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IEnumerable<ImageData> images = LoadImagesFromDirectory(folder: assetsRelativePath, useFolderNameAsLabel: true);\n",
    "display(images.Take(5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`IDataView`にデータをロードする。`IDataView`はLINQでいうところの`IEnumerable<T>`に相当する、ML.NETのデータの中心となる存在。 [参考](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.idataview?view=ml-dotnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 読み込んだImageDataをIDataViewにロード\n",
    "IDataView imageData = mlContext.Data.LoadFromEnumerable(images);\n",
    "// シャッフル\n",
    "IDataView shuffledData = mlContext.Data.ShuffleRows(imageData);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ラベルと画像を数値に変換する EstimatorChain\n",
    "var preprocessingPipeline = \n",
    "    mlContext.Transforms.Conversion\n",
    "    .MapValueToKey(\n",
    "        inputColumnName: \"Label\",\n",
    "        outputColumnName: \"LabelAsKey\")\n",
    "    .Append(mlContext.Transforms.LoadRawImageBytes(\n",
    "        outputColumnName: \"Image\",\n",
    "        imageFolder: assetsRelativePath,\n",
    "        inputColumnName: \"ImagePath\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 前処理\n",
    "IDataView preProcessedData = preprocessingPipeline\n",
    "                    .Fit(shuffledData)\n",
    "                    .Transform(shuffledData);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 訓練データとテストデータに分割\n",
    "TrainTestData trainSplit = mlContext.Data.TrainTestSplit(data: preProcessedData, testFraction: 0.3);\n",
    "TrainTestData validationTestSplit = mlContext.Data.TrainTestSplit(trainSplit.TestSet);\n",
    "\n",
    "IDataView trainSet = trainSplit.TrainSet;\n",
    "IDataView validationSet = validationTestSplit.TrainSet;\n",
    "IDataView testSet = validationTestSplit.TestSet;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## トレーニングパイプライン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "var classifierOptions = new ImageClassificationTrainer.Options()\n",
    "{\n",
    "    // 入力列\n",
    "    FeatureColumnName = \"Image\",\n",
    "    // ラベル\n",
    "    LabelColumnName = \"LabelAsKey\",\n",
    "    // 検量データセット\n",
    "    ValidationSet = validationSet,\n",
    "    // モデルアーキテクチャ（Resnet v2 を指定）\n",
    "    Arch = ImageClassificationTrainer.Architecture.ResnetV2101,\n",
    "    // トレーニング中の進捗記録用コールバック\n",
    "    MetricsCallback = (metrics) => Console.WriteLine(metrics),\n",
    "    // 検証セットがない時に訓練セットで検証\n",
    "    TestOnTrainSet = false,\n",
    "    // 後続の実行でボトルネックフェーズからキャッシュされた値を使うか\n",
    "    ReuseTrainSetBottleneckCachedValues = true,\n",
    "    ReuseValidationSetBottleneckCachedValues = true,\n",
    "    // 計算されたボトルネック値を格納するティレクトリ\n",
    "    WorkspacePath=workspaceRelativePath\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "var trainingPipeline = mlContext.MulticlassClassification.Trainers\n",
    "    .ImageClassification(classifierOptions)\n",
    "    .Append(mlContext.Transforms.Conversion.MapKeyToValue(\"PredictedLabel\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saver not created because there are no variables in the graph to restore\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:   0, Accuracy:  0.6916666\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:   1, Accuracy: 0.71250004\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:   2, Accuracy:  0.7541666\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:   3, Accuracy: 0.53333336\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:   4, Accuracy: 0.70416665\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:   5, Accuracy: 0.62500006\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:   6, Accuracy:  0.8083334\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:   7, Accuracy: 0.56666666\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:   8, Accuracy: 0.74583334\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:   9, Accuracy:        0.8\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  10, Accuracy:  0.7583334\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  11, Accuracy: 0.75833327\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  12, Accuracy: 0.54583335\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  13, Accuracy:  0.7833333\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  14, Accuracy:  0.7333333\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  15, Accuracy: 0.82500005\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  16, Accuracy:  0.7583334\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  17, Accuracy: 0.79583335\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  18, Accuracy: 0.82500005\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  19, Accuracy: 0.81250006\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  20, Accuracy:  0.8458333\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  21, Accuracy: 0.82916665\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  22, Accuracy: 0.84166664\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  23, Accuracy: 0.82083327\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  24, Accuracy: 0.84999996\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  25, Accuracy:  0.8416667\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  26, Accuracy: 0.84583336\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  27, Accuracy:  0.8500001\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  28, Accuracy:  0.8333333\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  29, Accuracy: 0.85833335\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  30, Accuracy:  0.8458333\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  31, Accuracy:  0.8416667\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  32, Accuracy: 0.84999996\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  33, Accuracy: 0.74166673\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  34, Accuracy:  0.8416667\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  35, Accuracy:  0.8666666\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  36, Accuracy: 0.82916665\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  37, Accuracy:  0.7708333\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  38, Accuracy:  0.7916667\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  39, Accuracy: 0.82916665\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  40, Accuracy:  0.8666666\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  41, Accuracy:  0.8416667\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  42, Accuracy: 0.84999996\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  43, Accuracy:  0.7541666\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  44, Accuracy: 0.82083327\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  45, Accuracy: 0.84166664\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  46, Accuracy: 0.84166664\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  47, Accuracy:  0.8541667\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  48, Accuracy:      0.825\n",
      "Phase: Training, Dataset used: Validation, Batch Processed Count:  12, Epoch:  49, Accuracy:  0.8333333\n",
      "Saver not created because there are no variables in the graph to restore\n",
      "Restoring parameters from C:\\Data\\Study\\Jupyter\\jupyter_notes\\notes_dotnet\\MLNet\\workspace\\custom_retrained_model_based_on_resnet_v2_101_299.meta\n",
      "Froze 2 variables.\n",
      "Converted 2 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "ITransformer trainedModel = trainingPipeline.Fit(trainSet);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "private static void OutputPrediction(ModelOutput prediction)\n",
    "{\n",
    "    string imageName = Path.GetFileName(prediction.ImagePath);\n",
    "    Console.WriteLine($\"Image: {imageName} | Actual Value: {prediction.Label} | Predicted Value: {prediction.PredictedLabel}\");\n",
    "}\n",
    "\n",
    "public static void ClassifySingleImage(MLContext mlContext, IDataView data, ITransformer trainedModel)\n",
    "{\n",
    "    PredictionEngine<ModelInput, ModelOutput> predictionEngine = mlContext.Model.CreatePredictionEngine<ModelInput, ModelOutput>(trainedModel);\n",
    "    ModelInput image = mlContext.Data.CreateEnumerable<ModelInput>(data,reuseRowObject:true).First();\n",
    "    \n",
    "    // Prediction\n",
    "    ModelOutput prediction = predictionEngine.Predict(image);\n",
    "    \n",
    "    Console.WriteLine(\"Classifying single image\");\n",
    "    OutputPrediction(prediction);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying single image\n",
      "Image: 7001-120.jpg | Actual Value: UD | Predicted Value: CD\n"
     ]
    }
   ],
   "source": [
    "ClassifySingleImage(mlContext, testSet, trainedModel);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 複数枚予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "public static void ClassifyImages(MLContext mlContext, IDataView data, ITransformer trainedModel)\n",
    "{\n",
    "    IDataView predictionData = trainedModel.Transform(data);\n",
    "    IEnumerable<ModelOutput> predictions = mlContext.Data.CreateEnumerable<ModelOutput>(predictionData, reuseRowObject: true).Take(10);\n",
    "    Console.WriteLine(\"Classifying multiple images\");\n",
    "    foreach (var prediction in predictions)\n",
    "    {\n",
    "        OutputPrediction(prediction);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying multiple images\n",
      "Image: 7001-120.jpg | Actual Value: UD | Predicted Value: CD\n",
      "Image: 7005-80.jpg | Actual Value: CD | Predicted Value: UD\n",
      "Image: 7002-194.jpg | Actual Value: CD | Predicted Value: UD\n",
      "Image: 7001-228.jpg | Actual Value: UD | Predicted Value: CD\n",
      "Image: 7001-211.jpg | Actual Value: UD | Predicted Value: CD\n",
      "Image: 7001-42.jpg | Actual Value: CD | Predicted Value: UD\n"
     ]
    }
   ],
   "source": [
    "ClassifyImages(mlContext, testSet, trainedModel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "C#",
   "pygments_lexer": "csharp",
   "version": "8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
